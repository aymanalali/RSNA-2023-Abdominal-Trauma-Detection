{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#CROPING \n\n\nimport os\nimport glob\nimport nibabel as nib\nimport numpy as np\nfrom scipy.ndimage import binary_dilation\n\n# Define the paths to the directories containing images and masks\nimages_path = '/kaggle/input/plznew/img'\nmasks_path = '/kaggle/input/plznew/mask'\n\n# Get a list of all image and mask files in the directories\nimage_files = sorted(glob.glob(os.path.join(images_path, '*.nii')))\nmask_files = sorted(glob.glob(os.path.join(masks_path, '*.nii')))\n\n# Define the number of pixels to preserve around non-zero pixels\npreservation_radius = 5\n\n# Create the output directory if it doesn't exist\noutput_directory = '/kaggle/working/cropped'\nos.makedirs(output_directory, exist_ok=True)\n\n# Process each pair of image and mask files\nfor image_file, mask_file in zip(image_files, mask_files):\n    # Load the 3D medical image and the binary mask\n    image = nib.load(image_file).get_fdata()\n    mask = nib.load(mask_file).get_fdata()\n\n    # Element-wise multiplication with the binary mask\n    masked_image = image * mask\n\n    # Create a preservation mask using binary dilation\n    preservation_mask = binary_dilation(mask, iterations=preservation_radius)\n\n    # Blend the preserved region from the original image with the masked region\n    preserved_image = masked_image.copy()\n    preserved_image[preservation_mask] = image[preservation_mask]\n\n    # Get the filename (without the path) to use for saving\n    output_filename = os.path.basename(image_file)\n\n    # Save the resulting image in the output directory\n    output_path = os.path.join(output_directory, output_filename)\n    nib.save(nib.Nifti1Image(preserved_image, np.eye(4)), output_path)\n\n    print(f\"Cropped and preserved image saved to {output_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:31:06.883225Z","iopub.execute_input":"2023-10-02T11:31:06.883595Z","iopub.status.idle":"2023-10-02T11:36:53.011785Z","shell.execute_reply.started":"2023-10-02T11:31:06.883567Z","shell.execute_reply":"2023-10-02T11:36:53.010378Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cropped and preserved image saved to /kaggle/working/cropped/10000.nii\nCropped and preserved image saved to /kaggle/working/cropped/10109.nii\nCropped and preserved image saved to /kaggle/working/cropped/10180.nii\nCropped and preserved image saved to /kaggle/working/cropped/10252.nii\nCropped and preserved image saved to /kaggle/working/cropped/10385.nii\nCropped and preserved image saved to /kaggle/working/cropped/10494.nii\nCropped and preserved image saved to /kaggle/working/cropped/11748.nii\nCropped and preserved image saved to /kaggle/working/cropped/1201.nii\nCropped and preserved image saved to /kaggle/working/cropped/12039.nii\nCropped and preserved image saved to /kaggle/working/cropped/12102.nii\nCropped and preserved image saved to /kaggle/working/cropped/12114.nii\nCropped and preserved image saved to /kaggle/working/cropped/12402.nii\nCropped and preserved image saved to /kaggle/working/cropped/12674.nii\nCropped and preserved image saved to /kaggle/working/cropped/12840.nii\nCropped and preserved image saved to /kaggle/working/cropped/12900.nii\nCropped and preserved image saved to /kaggle/working/cropped/13041.nii\nCropped and preserved image saved to /kaggle/working/cropped/13307.nii\nCropped and preserved image saved to /kaggle/working/cropped/13666.nii\nCropped and preserved image saved to /kaggle/working/cropped/137.nii\nCropped and preserved image saved to /kaggle/working/cropped/13774.nii\nCropped and preserved image saved to /kaggle/working/cropped/13848.nii\nCropped and preserved image saved to /kaggle/working/cropped/13925.nii\nCropped and preserved image saved to /kaggle/working/cropped/14286.nii\nCropped and preserved image saved to /kaggle/working/cropped/15271.nii\nCropped and preserved image saved to /kaggle/working/cropped/15415.nii\nCropped and preserved image saved to /kaggle/working/cropped/15539.nii\nCropped and preserved image saved to /kaggle/working/cropped/15748.nii\nCropped and preserved image saved to /kaggle/working/cropped/16066.nii\nCropped and preserved image saved to /kaggle/working/cropped/16097.nii\nCropped and preserved image saved to /kaggle/working/cropped/16503.nii\nCropped and preserved image saved to /kaggle/working/cropped/17225.nii\nCropped and preserved image saved to /kaggle/working/cropped/17577.nii\nCropped and preserved image saved to /kaggle/working/cropped/17605.nii\nCropped and preserved image saved to /kaggle/working/cropped/18207.nii\nCropped and preserved image saved to /kaggle/working/cropped/18624.nii\nCropped and preserved image saved to /kaggle/working/cropped/19360.nii\nCropped and preserved image saved to /kaggle/working/cropped/19468.nii\nCropped and preserved image saved to /kaggle/working/cropped/19657.nii\nCropped and preserved image saved to /kaggle/working/cropped/19927.nii\nCropped and preserved image saved to /kaggle/working/cropped/20664.nii\nCropped and preserved image saved to /kaggle/working/cropped/20684.nii\nCropped and preserved image saved to /kaggle/working/cropped/21057.nii\nCropped and preserved image saved to /kaggle/working/cropped/21282.nii\nCropped and preserved image saved to /kaggle/working/cropped/22232.nii\nCropped and preserved image saved to /kaggle/working/cropped/22397.nii\nCropped and preserved image saved to /kaggle/working/cropped/22479.nii\nCropped and preserved image saved to /kaggle/working/cropped/22730.nii\nCropped and preserved image saved to /kaggle/working/cropped/23644.nii\nCropped and preserved image saved to /kaggle/working/cropped/23837.nii\nCropped and preserved image saved to /kaggle/working/cropped/24134.nii\nCropped and preserved image saved to /kaggle/working/cropped/24149.nii\nCropped and preserved image saved to /kaggle/working/cropped/24373.nii\nCropped and preserved image saved to /kaggle/working/cropped/24442.nii\nCropped and preserved image saved to /kaggle/working/cropped/24645.nii\nCropped and preserved image saved to /kaggle/working/cropped/24774.nii\nCropped and preserved image saved to /kaggle/working/cropped/25349.nii\nCropped and preserved image saved to /kaggle/working/cropped/25359.nii\nCropped and preserved image saved to /kaggle/working/cropped/26214.nii\nCropped and preserved image saved to /kaggle/working/cropped/26343.nii\nCropped and preserved image saved to /kaggle/working/cropped/26840.nii\nCropped and preserved image saved to /kaggle/working/cropped/26906.nii\nCropped and preserved image saved to /kaggle/working/cropped/26942.nii\nCropped and preserved image saved to /kaggle/working/cropped/26980.nii\nCropped and preserved image saved to /kaggle/working/cropped/28079.nii\nCropped and preserved image saved to /kaggle/working/cropped/28122.nii\nCropped and preserved image saved to /kaggle/working/cropped/28432.nii\nCropped and preserved image saved to /kaggle/working/cropped/29053.nii\nCropped and preserved image saved to /kaggle/working/cropped/29167.nii\nCropped and preserved image saved to /kaggle/working/cropped/29832.nii\nCropped and preserved image saved to /kaggle/working/cropped/30064.nii\nCropped and preserved image saved to /kaggle/working/cropped/30522.nii\nCropped and preserved image saved to /kaggle/working/cropped/30843.nii\nCropped and preserved image saved to /kaggle/working/cropped/30902.nii\nCropped and preserved image saved to /kaggle/working/cropped/30952.nii\nCropped and preserved image saved to /kaggle/working/cropped/31021.nii\nCropped and preserved image saved to /kaggle/working/cropped/31085.nii\nCropped and preserved image saved to /kaggle/working/cropped/31146.nii\nCropped and preserved image saved to /kaggle/working/cropped/31200.nii\nCropped and preserved image saved to /kaggle/working/cropped/31571.nii\nCropped and preserved image saved to /kaggle/working/cropped/31852.nii\nCropped and preserved image saved to /kaggle/working/cropped/32243.nii\nCropped and preserved image saved to /kaggle/working/cropped/32670.nii\nCropped and preserved image saved to /kaggle/working/cropped/32991.nii\nCropped and preserved image saved to /kaggle/working/cropped/33355.nii\nCropped and preserved image saved to /kaggle/working/cropped/33526.nii\nCropped and preserved image saved to /kaggle/working/cropped/34224.nii\nCropped and preserved image saved to /kaggle/working/cropped/34232.nii\nCropped and preserved image saved to /kaggle/working/cropped/34774.nii\nCropped and preserved image saved to /kaggle/working/cropped/35190.nii\nCropped and preserved image saved to /kaggle/working/cropped/35661.nii\nCropped and preserved image saved to /kaggle/working/cropped/36257.nii\nCropped and preserved image saved to /kaggle/working/cropped/36753.nii\nCropped and preserved image saved to /kaggle/working/cropped/37032.nii\nCropped and preserved image saved to /kaggle/working/cropped/38633.nii\nCropped and preserved image saved to /kaggle/working/cropped/39013.nii\nCropped and preserved image saved to /kaggle/working/cropped/39205.nii\nCropped and preserved image saved to /kaggle/working/cropped/39222.nii\nCropped and preserved image saved to /kaggle/working/cropped/39628.nii\nCropped and preserved image saved to /kaggle/working/cropped/397.nii\nCropped and preserved image saved to /kaggle/working/cropped/39864.nii\nCropped and preserved image saved to /kaggle/working/cropped/40186.nii\nCropped and preserved image saved to /kaggle/working/cropped/40430.nii\nCropped and preserved image saved to /kaggle/working/cropped/40471.nii\nCropped and preserved image saved to /kaggle/working/cropped/40496.nii\nCropped and preserved image saved to /kaggle/working/cropped/40781.nii\nCropped and preserved image saved to /kaggle/working/cropped/4123.nii\nCropped and preserved image saved to /kaggle/working/cropped/41288.nii\nCropped and preserved image saved to /kaggle/working/cropped/41663.nii\nCropped and preserved image saved to /kaggle/working/cropped/41976.nii\nCropped and preserved image saved to /kaggle/working/cropped/42173.nii\nCropped and preserved image saved to /kaggle/working/cropped/42680.nii\nCropped and preserved image saved to /kaggle/working/cropped/42973.nii\nCropped and preserved image saved to /kaggle/working/cropped/43088.nii\nCropped and preserved image saved to /kaggle/working/cropped/43233.nii\nCropped and preserved image saved to /kaggle/working/cropped/43416.nii\nCropped and preserved image saved to /kaggle/working/cropped/44612.nii\nCropped and preserved image saved to /kaggle/working/cropped/44712.nii\nCropped and preserved image saved to /kaggle/working/cropped/44758.nii\nCropped and preserved image saved to /kaggle/working/cropped/45406.nii\nCropped and preserved image saved to /kaggle/working/cropped/4622.nii\nCropped and preserved image saved to /kaggle/working/cropped/46912.nii\nCropped and preserved image saved to /kaggle/working/cropped/47155.nii\nCropped and preserved image saved to /kaggle/working/cropped/47305.nii\nCropped and preserved image saved to /kaggle/working/cropped/47438.nii\nCropped and preserved image saved to /kaggle/working/cropped/4759.nii\nCropped and preserved image saved to /kaggle/working/cropped/47610.nii\nCropped and preserved image saved to /kaggle/working/cropped/47775.nii\nCropped and preserved image saved to /kaggle/working/cropped/47856.nii\nCropped and preserved image saved to /kaggle/working/cropped/48324.nii\nCropped and preserved image saved to /kaggle/working/cropped/4890.nii\nCropped and preserved image saved to /kaggle/working/cropped/48901.nii\nCropped and preserved image saved to /kaggle/working/cropped/4929.nii\nCropped and preserved image saved to /kaggle/working/cropped/49547.nii\nCropped and preserved image saved to /kaggle/working/cropped/49753.nii\nCropped and preserved image saved to /kaggle/working/cropped/50212.nii\nCropped and preserved image saved to /kaggle/working/cropped/50434.nii\nCropped and preserved image saved to /kaggle/working/cropped/50875.nii\nCropped and preserved image saved to /kaggle/working/cropped/5103.nii\nCropped and preserved image saved to /kaggle/working/cropped/51033.nii\nCropped and preserved image saved to /kaggle/working/cropped/5104.nii\nCropped and preserved image saved to /kaggle/working/cropped/51136.nii\nCropped and preserved image saved to /kaggle/working/cropped/51141.nii\nCropped and preserved image saved to /kaggle/working/cropped/5118.nii\nCropped and preserved image saved to /kaggle/working/cropped/5176.nii\nCropped and preserved image saved to /kaggle/working/cropped/5218.nii\nCropped and preserved image saved to /kaggle/working/cropped/52279.nii\nCropped and preserved image saved to /kaggle/working/cropped/525.nii\nCropped and preserved image saved to /kaggle/working/cropped/5260.nii\nCropped and preserved image saved to /kaggle/working/cropped/527.nii\nCropped and preserved image saved to /kaggle/working/cropped/52940.nii\nCropped and preserved image saved to /kaggle/working/cropped/52961.nii\nCropped and preserved image saved to /kaggle/working/cropped/52970.nii\nCropped and preserved image saved to /kaggle/working/cropped/53000.nii\nCropped and preserved image saved to /kaggle/working/cropped/53345.nii\nCropped and preserved image saved to /kaggle/working/cropped/53843.nii\nCropped and preserved image saved to /kaggle/working/cropped/5425.nii\nCropped and preserved image saved to /kaggle/working/cropped/54830.nii\nCropped and preserved image saved to /kaggle/working/cropped/54917.nii\nCropped and preserved image saved to /kaggle/working/cropped/55449.nii\nCropped and preserved image saved to /kaggle/working/cropped/55515.nii\nCropped and preserved image saved to /kaggle/working/cropped/55583.nii\nCropped and preserved image saved to /kaggle/working/cropped/55694.nii\nCropped and preserved image saved to /kaggle/working/cropped/55928.nii\nCropped and preserved image saved to /kaggle/working/cropped/55965.nii\nCropped and preserved image saved to /kaggle/working/cropped/56245.nii\nCropped and preserved image saved to /kaggle/working/cropped/57769.nii\nCropped and preserved image saved to /kaggle/working/cropped/58027.nii\nCropped and preserved image saved to /kaggle/working/cropped/58391.nii\nCropped and preserved image saved to /kaggle/working/cropped/58548.nii\nCropped and preserved image saved to /kaggle/working/cropped/58697.nii\nCropped and preserved image saved to /kaggle/working/cropped/59325.nii\nCropped and preserved image saved to /kaggle/working/cropped/60302.nii\nCropped and preserved image saved to /kaggle/working/cropped/60307.nii\nCropped and preserved image saved to /kaggle/working/cropped/60755.nii\nCropped and preserved image saved to /kaggle/working/cropped/60881.nii\nCropped and preserved image saved to /kaggle/working/cropped/60961.nii\nCropped and preserved image saved to /kaggle/working/cropped/6130.nii\nCropped and preserved image saved to /kaggle/working/cropped/61403.nii\nCropped and preserved image saved to /kaggle/working/cropped/61569.nii\nCropped and preserved image saved to /kaggle/working/cropped/61670.nii\nCropped and preserved image saved to /kaggle/working/cropped/6172.nii\nCropped and preserved image saved to /kaggle/working/cropped/61747.nii\nCropped and preserved image saved to /kaggle/working/cropped/62307.nii\nCropped and preserved image saved to /kaggle/working/cropped/62556.nii\nCropped and preserved image saved to /kaggle/working/cropped/62573.nii\nCropped and preserved image saved to /kaggle/working/cropped/62680.nii\nCropped and preserved image saved to /kaggle/working/cropped/6305.nii\nCropped and preserved image saved to /kaggle/working/cropped/63146.nii\nCropped and preserved image saved to /kaggle/working/cropped/63205.nii\nCropped and preserved image saved to /kaggle/working/cropped/63418.nii\nCropped and preserved image saved to /kaggle/working/cropped/6344.nii\nCropped and preserved image saved to /kaggle/working/cropped/63701.nii\nCropped and preserved image saved to /kaggle/working/cropped/63843.nii\nCropped and preserved image saved to /kaggle/working/cropped/64117.nii\nCropped and preserved image saved to /kaggle/working/cropped/64520.nii\nCropped and preserved image saved to /kaggle/working/cropped/6575.nii\nCropped and preserved image saved to /kaggle/working/cropped/6631.nii\nCropped and preserved image saved to /kaggle/working/cropped/7334.nii\nCropped and preserved image saved to /kaggle/working/cropped/7384.nii\nCropped and preserved image saved to /kaggle/working/cropped/7397.nii\nCropped and preserved image saved to /kaggle/working/cropped/778.nii\nCropped and preserved image saved to /kaggle/working/cropped/7818.nii\nCropped and preserved image saved to /kaggle/working/cropped/8236.nii\nCropped and preserved image saved to /kaggle/working/cropped/8320.nii\nCropped and preserved image saved to /kaggle/working/cropped/8340.nii\nCropped and preserved image saved to /kaggle/working/cropped/8413.nii\n","output_type":"stream"}]},{"cell_type":"code","source":"#CONVERT TO FLOAT32\n\n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Specify the input directory\ninput_dir = '/kaggle/working/cropped'\n\n# Function to convert NII files to float32\ndef convert_to_float32(file_path):\n    # Load the NII image\n    image = nib.load(file_path)\n    image_data = image.get_fdata().astype(np.float32)  # Convert to float32\n\n    # Save the updated image with float32 data type\n    new_image = nib.Nifti1Image(image_data, image.affine)\n    new_image.to_filename(file_path)\n\n# Process and convert each NII image in the input directory\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.nii'):\n        file_path = os.path.join(input_dir, file_name)\n        convert_to_float32(file_path)\n\nprint(\"Conversion to float32 completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:41:32.585864Z","iopub.execute_input":"2023-10-02T11:41:32.587336Z","iopub.status.idle":"2023-10-02T11:42:06.457197Z","shell.execute_reply.started":"2023-10-02T11:41:32.587278Z","shell.execute_reply":"2023-10-02T11:42:06.456053Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Conversion to float32 completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"#REMOVE BLACK SLICES + WHAT IS THE ONE WITH MOST SLICES \n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Specify the input directory\ninput_dir = '/kaggle/working/cropped'\n\n# Function to remove completely dark slices from an image\ndef remove_dark_slices(image_data):\n    # Calculate the mean intensity of each slice\n    slice_means = np.mean(image_data, axis=(0, 1))\n    \n    # Identify dark slices (where the mean intensity is below a threshold)\n    threshold = 1.0  # Adjust this threshold as needed\n    dark_slice_indices = np.where(slice_means < threshold)[0]\n    \n    # Remove the dark slices from the image\n    cleaned_image_data = np.delete(image_data, dark_slice_indices, axis=2)\n    \n    return cleaned_image_data, dark_slice_indices\n\n# Process each NII image in the input directory\nmax_slices = 0\nimage_with_most_slices = \"\"\n\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.nii'):\n        file_path = os.path.join(input_dir, file_name)\n        \n        # Load the NII image\n        image = nib.load(file_path)\n        image_data = image.get_fdata()\n        \n        # Remove dark slices\n        cleaned_image_data, dark_slice_indices = remove_dark_slices(image_data)\n        \n        # Update the image if it has more slices than the current max\n        if cleaned_image_data.shape[2] > max_slices:\n            max_slices = cleaned_image_data.shape[2]\n            image_with_most_slices = file_name\n        \n        # Save the cleaned image back\n        cleaned_image = nib.Nifti1Image(cleaned_image_data, image.affine)\n        cleaned_image.to_filename(file_path)\n\nprint(f\"Images processed. Image with the most remaining slices: {image_with_most_slices}, Number of Slices: {max_slices}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:42:06.459771Z","iopub.execute_input":"2023-10-02T11:42:06.460375Z","iopub.status.idle":"2023-10-02T11:42:49.899534Z","shell.execute_reply.started":"2023-10-02T11:42:06.460324Z","shell.execute_reply":"2023-10-02T11:42:49.898371Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Images processed. Image with the most remaining slices: 51033.nii, Number of Slices: 976\n","output_type":"stream"}]},{"cell_type":"code","source":"#CONVERT TO FLOAT32\n\n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Specify the input directory\ninput_dir = '/kaggle/working/cropped'\n\n# Function to convert NII files to float32\ndef convert_to_float32(file_path):\n    # Load the NII image\n    image = nib.load(file_path)\n    image_data = image.get_fdata().astype(np.float32)  # Convert to float32\n\n    # Save the updated image with float32 data type\n    new_image = nib.Nifti1Image(image_data, image.affine)\n    new_image.to_filename(file_path)\n\n# Process and convert each NII image in the input directory\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.nii'):\n        file_path = os.path.join(input_dir, file_name)\n        convert_to_float32(file_path)\n\nprint(\"Conversion to float32 completed.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:43:36.365820Z","iopub.execute_input":"2023-10-02T11:43:36.366193Z","iopub.status.idle":"2023-10-02T11:43:52.149018Z","shell.execute_reply.started":"2023-10-02T11:43:36.366167Z","shell.execute_reply":"2023-10-02T11:43:52.147416Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Conversion to float32 completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"#NORMALIZE PICS\n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Define the directory where the weighted images are saved\noutput_directory = '/kaggle/working/cropped'  # Change to your output directory\n\n# List all weighted image files in the directory\nweighted_files = [file for file in os.listdir(output_directory) if file.endswith('.nii')]\n\n# Loop through each weighted image file\nfor weighted_file in weighted_files:\n    # Load the weighted CT scan\n    weighted_ct_scan = nib.load(os.path.join(output_directory, weighted_file))\n    weighted_ct_data = weighted_ct_scan.get_fdata()\n\n    # Normalize voxel values to have mean zero and unit variance\n    mean = np.mean(weighted_ct_data)\n    std = np.std(weighted_ct_data)\n    normalized_weighted_ct_data = (weighted_ct_data - mean) / std\n\n    # Save the normalized result, overwriting the existing file\n    normalized_weighted_nii = nib.Nifti1Image(normalized_weighted_ct_data, affine=weighted_ct_scan.affine)\n    nib.save(normalized_weighted_nii, os.path.join(output_directory, weighted_file))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:44:22.247573Z","iopub.execute_input":"2023-10-02T11:44:22.247941Z","iopub.status.idle":"2023-10-02T11:44:58.933245Z","shell.execute_reply.started":"2023-10-02T11:44:22.247914Z","shell.execute_reply":"2023-10-02T11:44:58.931712Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#CONVERT TO FLOAT32\n\n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Specify the input directory\ninput_dir = '/kaggle/working/cropped'\n\n# Function to convert NII files to float32\ndef convert_to_float32(file_path):\n    # Load the NII image\n    image = nib.load(file_path)\n    image_data = image.get_fdata().astype(np.float32)  # Convert to float32\n\n    # Save the updated image with float32 data type\n    new_image = nib.Nifti1Image(image_data, image.affine)\n    new_image.to_filename(file_path)\n\n# Process and convert each NII image in the input directory\nfor file_name in os.listdir(input_dir):\n    if file_name.endswith('.nii'):\n        file_path = os.path.join(input_dir, file_name)\n        convert_to_float32(file_path)\n\nprint(\"Conversion to float32 completed.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:45:26.941977Z","iopub.execute_input":"2023-10-02T11:45:26.942323Z","iopub.status.idle":"2023-10-02T11:45:42.270714Z","shell.execute_reply.started":"2023-10-02T11:45:26.942297Z","shell.execute_reply":"2023-10-02T11:45:42.269331Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Conversion to float32 completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\n\n# Function to crop and pad a 3D NIfTI image to the target shape\ndef crop_and_pad_nifti(input_path, output_path, target_shape):\n    # Load the NIfTI image\n    img = nib.load(input_path)\n    data = img.get_fdata().astype(np.float32)  # Convert to float32\n    \n    # Get the current shape of the image\n    current_shape = data.shape\n\n    # Calculate the variance of pixel values along the slice axis\n    slice_variances = np.var(data, axis=(0, 1))\n\n    # Identify slices with low variance\n    threshold = np.percentile(slice_variances, 10)  # Adjust the percentile as needed\n    low_variance_slices = slice_variances < threshold\n\n    # Remove slices with low variance\n    data = data[:, :, ~low_variance_slices]\n\n    # Calculate the number of slices to pad or crop\n    num_slices_to_pad_or_crop = target_shape[2] - data.shape[2]\n\n    if num_slices_to_pad_or_crop > 0:\n        # Padding: add slices with zeros at the end\n        pad_width = ((0, 0), (0, 0), (0, num_slices_to_pad_or_crop))\n        data = np.pad(data, pad_width, mode='constant')\n    elif num_slices_to_pad_or_crop < 0:\n        # Cropping: remove excess slices\n        data = data[:, :, :target_shape[2]]\n\n    # Create a new NIfTI image with the modified data\n    new_img = nib.Nifti1Image(data, img.affine)\n\n    # Save the modified image to the output path\n    nib.save(new_img, output_path)\n\n# Specify the directory containing the input NIfTI files\ninput_directory = '/kaggle/working/cropped'\n\n# Specify the target shape\ntarget_shape = (128, 128, 512)\n\n# Specify the output directory for saving modified images\noutput_directory = '/kaggle/working/cropped_output'\nos.makedirs(output_directory, exist_ok=True)\n\n# Iterate through all files in the input directory\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.nii'):\n        input_path = os.path.join(input_directory, filename)\n        output_path = os.path.join(output_directory, filename)\n        crop_and_pad_nifti(input_path, output_path, target_shape)\n\n# Print a message when the processing is complete\nprint(\"Processing complete.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T11:46:12.384371Z","iopub.execute_input":"2023-10-02T11:46:12.384760Z","iopub.status.idle":"2023-10-02T11:46:31.759110Z","shell.execute_reply.started":"2023-10-02T11:46:12.384731Z","shell.execute_reply":"2023-10-02T11:46:31.757979Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Processing complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"#DELET PICS\n\n\nimport shutil\n\n# Directory path\ndirectory_to_delete = '/kaggle/working/padded_images1'\n# Use shutil.rmtree to delete the entire directory and its contents\nshutil.rmtree(directory_to_delete)\n\n# Recreate the directory if needed\n# os.makedirs(directory_to_delete)  # Uncomment this line if you want to recreate the directory\n\nprint(f\"Contents of '{directory_to_delete}' have been deleted.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PREDICT \n\n\n\nimport os\nimport numpy as np\nimport nibabel as nib\nfrom tensorflow import keras\n\n# Define the NII image path\nimage_path = '/kaggle/working/processed_images4/48901.nii'  # Update with the path to your NII image\n\n# Function to load and preprocess NII image\ndef load_and_preprocess_image(image_path):\n    image = nib.load(image_path).get_fdata().astype(np.float32)\n    # Add preprocessing steps if necessary (e.g., resizing, normalization)\n    # Ensure the shape matches the input shape expected by your model\n    # Add an extra dimension for the channel if necessary\n    return image[..., np.newaxis]\n\n# Load and preprocess the NII image\ninput_image = load_and_preprocess_image(image_path)\n\n# Make predictions using your trained model (assuming the model is already loaded)\npredictions = model.predict(np.expand_dims(input_image, axis=0))\n\n# Apply a threshold of 0.5 to get binary results (0 or 1)\nbinary_predictions = (predictions >= 0.5).astype(int)\n\n# The binary_predictions will be a binary array for each of the 14 criteria\nprint(binary_predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DETECT IMAGES SHAPE\n\n\nimport os\nimport nibabel as nib\n\n# Specify the directory path\ndirectory_path = '/kaggle/working/padded_images1'\n\n# Get a list of all NII files in the directory\nnii_files = [file for file in os.listdir(directory_path) if file.endswith('.nii')]\n\n# Iterate through the NII files and print their shapes\nfor file_name in nii_files:\n    file_path = os.path.join(directory_path, file_name)\n    \n    # Load the NII image\n    image = nib.load(file_path)\n    \n    # Get the shape of the image data\n    image_shape = image.get_fdata().shape\n    \n    # Print the file name and its shape\n    print(f\"File: {file_name}, Shape: {image_shape}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TYPE 32, 64\n\n\n\nimport os\nimport nibabel as nib\n\n# Directory containing the NIfTI files\ndirectory_path = '/kaggle/working/padded_images1'  # Replace with your directory path\n\n# Get a list of all NIfTI files in the directory\nnifti_files = [file for file in os.listdir(directory_path) if file.endswith('.nii')]\n\n# Dictionary to store data types for each file\ndata_types = {}\n\n# Loop through each NIfTI file and determine its data type\nfor file_name in nifti_files:\n    file_path = os.path.join(directory_path, file_name)\n\n    # Load the NIfTI file\n    img = nib.load(file_path)\n\n    # Get the data type of the NIfTI data\n    data_type = str(img.get_data_dtype())\n\n    # Store the data type in the dictionary\n    data_types[file_name] = data_type\n\n# Print the data types for each file\nfor file_name, data_type in data_types.items():\n    print(f\"{file_name}: {data_type}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CROP AND PAD TO MAKE ALL PICS IN CERTAIN SHAPE  \n\n\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# Specify the input and output directories\ninput_dir = '/kaggle/input/croped/cropped'  # Input directory containing NII images\noutput_dir = '/kaggle/working/processed_images/'  # Output directory for processed images\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Define the target size (128, 128, 512)\ntarget_size = (128, 128, 256)\n\n# Function to resize or pad images to the target size and save them\ndef resize_or_pad_and_save(image_path, output_dir, target_size):\n    # Load the NII image\n    image = nib.load(image_path)\n    image_data = image.get_fdata().astype(np.float32)  # Ensure float32 data type\n\n    # Check if the image size matches the target size\n    if image_data.shape == target_size:\n        # If already at the target size, copy the image to the output directory\n        destination_path = os.path.join(output_dir, os.path.basename(image_path))\n        nib.save(image, destination_path)\n    else:\n        # Determine whether to resize or pad based on image size\n        if image_data.shape[0] >= target_size[0] and image_data.shape[1] >= target_size[1] and image_data.shape[2] >= target_size[2]:\n            # Crop or resize the image to the target size\n            processed_image_data = image_data[:target_size[0], :target_size[1], :target_size[2]]\n        else:\n            # Pad the image to the target size\n            pad_width = [(0, max(target_size[0] - image_data.shape[0], 0)),\n                         (0, max(target_size[1] - image_data.shape[1], 0)),\n                         (0, max(target_size[2] - image_data.shape[2], 0))]\n            processed_image_data = np.pad(image_data, pad_width, mode='constant', constant_values=0)\n\n        # Create a new Nifti1Image object with the processed data\n        processed_image = nib.Nifti1Image(processed_image_data, image.affine)\n\n        # Save the processed image with float32 data type\n        destination_path = os.path.join(output_dir, os.path.basename(image_path))\n        nib.save(processed_image, destination_path)\n\n# Process and resize/pad each NII image in the input directory\nfor image_file in os.listdir(input_dir):\n    if image_file.endswith('.nii'):\n        image_path = os.path.join(input_dir, image_file)\n        resize_or_pad_and_save(image_path, output_dir, target_size)\n\nprint(\"Processing completed.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T19:38:29.866474Z","iopub.execute_input":"2023-10-01T19:38:29.867176Z","iopub.status.idle":"2023-10-01T19:40:25.839280Z","shell.execute_reply.started":"2023-10-01T19:38:29.867140Z","shell.execute_reply":"2023-10-01T19:40:25.838269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#THE MODEL \n\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Define constants\ndata_dir = '/kaggle/input/croped256/processed_images'\nlabel_file = '/kaggle/input/labeeel/label.csv'\nimage_shape = (128, 128, 256, 1)  # Add an extra dimension for the channel\nnum_classes = 14\nbatch_size = 2\nepochs = 30\n\n# Load labels from CSV\nlabels_df = pd.read_csv(label_file)\nseries_ids = labels_df['series_id'].tolist()\nlabels = labels_df.iloc[:, 1:].values.astype(np.float32)\n\n# Function to load and preprocess NII images\ndef load_and_preprocess_image(series_id):\n    image_path = os.path.join(data_dir, f'{series_id}.nii')\n    image = nib.load(image_path).get_fdata().astype(np.float32)\n    # Add preprocessing steps if necessary (e.g., normalization)\n    return image[..., np.newaxis]  # Add an extra dimension for the channel\n\n# Create a custom data generator using tf.data\ndef data_generator(series_ids, labels, batch_size, shuffle=True):\n    num_samples = len(series_ids)\n    indices = list(range(num_samples))\n    if shuffle:\n        np.random.shuffle(indices)\n\n    for start_idx in range(0, num_samples, batch_size):\n        end_idx = min(start_idx + batch_size, num_samples)\n        batch_indices = indices[start_idx:end_idx]\n        batch_series_ids = [series_ids[i] for i in batch_indices]\n        batch_labels = labels[batch_indices]\n        batch_images = [load_and_preprocess_image(series_id) for series_id in batch_series_ids]\n        yield np.array(batch_images), batch_labels\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(series_ids, labels, test_size=0.2, random_state=42)\n\n# Define the multi-label binary classification model\ndef create_model():\n    model = keras.Sequential([\n        model = keras.Sequential([\n    layers.Input(shape=image_shape),\n    layers.Conv3D(16, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Conv3D(512, (3, 3, 3), activation='relu', padding='same'),\n    layers.MaxPooling3D((2, 2, 2)),\n    layers.Flatten(),\n    layers.Dense(1024, activation='relu'),\n    layers.Dense(num_classes, activation='sigmoid')\n])\n  # Sigmoid for multi-label binary classification\n    ])\n    return model\n\n# Create MirroredStrategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n\n# Create and compile the model within the strategy's scope\nwith strategy.scope():\n    model = create_model()\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model using the custom data generator\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: data_generator(X_train, y_train, batch_size),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *image_shape), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n    )\n)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: data_generator(X_val, y_val, batch_size, shuffle=False),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *image_shape), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n    )\n)\n\nmodel.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n\n# Evaluate the model\ny_pred = model.predict(val_dataset)\ny_pred_binary = (y_pred > 0.5).astype(int)\n\naccuracy = accuracy_score(y_val, y_pred_binary)\nprecision = precision_score(y_val, y_pred_binary, average='micro')\nrecall = recall_score(y_val, y_pred_binary, average='micro')\nf1 = f1_score(y_val, y_pred_binary, average='micro')\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:52:32.102509Z","iopub.execute_input":"2023-10-01T20:52:32.103019Z","iopub.status.idle":"2023-10-01T20:52:48.192877Z","shell.execute_reply.started":"2023-10-01T20:52:32.102987Z","shell.execute_reply":"2023-10-01T20:52:48.191100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Define constants\ndata_dir = '/kaggle/input/croped/processed_images'\nlabel_file = '/kaggle/input/labeeel/label.csv'\nimage_shape = (128, 128, 512, 1)  # Add an extra dimension for the channel\nnum_classes = 14\nbatch_size = 2\nepochs = 30\n\n# Load labels from CSV\nlabels_df = pd.read_csv(label_file)\nseries_ids = labels_df['series_id'].tolist()\nlabels = labels_df.iloc[:, 1:].values.astype(np.float32)\n\n# Function to load and preprocess NII images\ndef load_and_preprocess_image(series_id):\n    image_path = os.path.join(data_dir, f'{series_id}.nii')\n    image = nib.load(image_path).get_fdata().astype(np.float32)\n    # Add preprocessing steps if necessary (e.g., normalization)\n    return image[..., np.newaxis]  # Add an extra dimension for the channel\n\n# Create a custom data generator using tf.data\ndef data_generator(series_ids, labels, batch_size, shuffle=True):\n    num_samples = len(series_ids)\n    indices = list(range(num_samples))\n    if shuffle:\n        np.random.shuffle(indices)\n\n    for start_idx in range(0, num_samples, batch_size):\n        end_idx = min(start_idx + batch_size, num_samples)\n        batch_indices = indices[start_idx:end_idx]\n        batch_series_ids = [series_ids[i] for i in batch_indices]\n        batch_labels = labels[batch_indices]\n        batch_images = [load_and_preprocess_image(series_id) for series_id in batch_series_ids]\n        yield np.array(batch_images), batch_labels\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(series_ids, labels, test_size=0.2, random_state=42)\n\n# Define the multi-label binary classification model\ndef create_model():\n    model = keras.Sequential([\n        layers.Input(shape=image_shape),\n        layers.Conv3D(32, (3, 3, 3), activation='relu' ),\n        layers.MaxPooling3D((2, 2, 2) ),\n        layers.Conv3D(64, (3, 3, 3), activation='relu'),\n        layers.MaxPooling3D((2, 2, 2)),\n        layers.Conv3D(128, (3, 3, 3), activation='relu'),\n        layers.MaxPooling3D((2, 2, 2)),\n        layers.Conv3D(256, (3, 3, 3), activation='relu'),  # Missing closing parenthesis\n        layers.MaxPooling3D((2, 2, 2)),\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.Dense(num_classes, activation='sigmoid')\n    ])\n    return model\n\n# Create MirroredStrategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n\n# Create and compile the model within the strategy's scope\nwith strategy.scope():\n    model = create_model()\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model using the custom data generator\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: data_generator(X_train, y_train, batch_size),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *image_shape), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n    )\n)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: data_generator(X_val, y_val, batch_size, shuffle=False),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *image_shape), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n    )\n)\n\nmodel.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n\n# Evaluate the model\ny_pred = model.predict(val_dataset)\ny_pred_binary = (y_pred > 0.5).astype(int)\n\naccuracy = accuracy_score(y_val, y_pred_binary)\nprecision = precision_score(y_val, y_pred_binary, average='micro')\nrecall = recall_score(y_val, y_pred_binary, average='micro')\nf1 = f1_score(y_val, y_pred_binary, average='micro')\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:59:12.120868Z","iopub.execute_input":"2023-10-02T00:59:12.121108Z","iopub.status.idle":"2023-10-02T01:33:49.153703Z","shell.execute_reply.started":"2023-10-02T00:59:12.121069Z","shell.execute_reply":"2023-10-02T01:33:49.152426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\n\n# Function to crop and pad a 3D NIfTI image to the target shape\ndef crop_and_pad_nifti(input_path, output_path, target_shape):\n    # Load the NIfTI image\n    img = nib.load(input_path)\n    data = img.get_fdata().astype(np.float32)  # Convert to float32\n    \n    # Get the current shape of the image\n    current_shape = data.shape\n\n    # Calculate the variance of pixel values along the slice axis\n    slice_variances = np.var(data, axis=(0, 1))\n\n    # Identify slices with low variance\n    threshold = np.percentile(slice_variances, 10)  # Adjust the percentile as needed\n    low_variance_slices = slice_variances < threshold\n\n    # Remove slices with low variance\n    data = data[:, :, ~low_variance_slices]\n\n    # Calculate the number of slices to pad or crop\n    num_slices_to_pad_or_crop = target_shape[2] - data.shape[2]\n\n    if num_slices_to_pad_or_crop > 0:\n        # Padding: add slices with zeros at the end\n        pad_width = ((0, 0), (0, 0), (0, num_slices_to_pad_or_crop))\n        data = np.pad(data, pad_width, mode='constant')\n    elif num_slices_to_pad_or_crop < 0:\n        # Cropping: remove excess slices\n        data = data[:, :, :target_shape[2]]\n\n    # Create a new NIfTI image with the modified data\n    new_img = nib.Nifti1Image(data, img.affine)\n\n    # Save the modified image to the output path\n    nib.save(new_img, output_path)\n\n# Specify the directory containing the input NIfTI files\ninput_directory = '/kaggle/input/croped/cropped'\n\n# Specify the target shape\ntarget_shape = (128, 128, 512)\n\n# Specify the output directory for saving modified images\noutput_directory = '/kaggle/working/cropped_output'\nos.makedirs(output_directory, exist_ok=True)\n\n# Iterate through all files in the input directory\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.nii'):\n        input_path = os.path.join(input_directory, filename)\n        output_path = os.path.join(output_directory, filename)\n        crop_and_pad_nifti(input_path, output_path, target_shape)\n\n# Print a message when the processing is complete\nprint(\"Processing complete.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}